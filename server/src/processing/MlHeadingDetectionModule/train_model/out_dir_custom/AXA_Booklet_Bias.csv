"line","is_different_style","is_font_bigger","different_color","is_font_unique","text_case","word_count","is_number","nb_of_verbs","nb_of_nouns","nb_of_cardinal_numbers","label"
"Understanding","1","1","1","1","2","1","0","0","1","0","heading"
"and Mitigating Bias","1","1","1","1","2","3","0","0","1","0","heading"
"Understanding","1","1","0","1","2","1","0","0","1","0","heading"
"and","1","1","0","1","0","1","0","0","0","0","heading"
"Mitigating Bias","1","1","0","1","2","2","0","1","1","0","heading"
"1. Foreword","1","1","1","0","2","2","0","0","0","1","heading"
"Machine learning (ML) algorithms identify pattern in data. Its","0","0","0","1","3","9","0","1","4","0","paragraph"
"major strength is the desired capability to find and discriminate","0","0","0","1","0","10","0","3","2","0","paragraph"
"classes in training data, and to use those insights to make predic-","0","0","0","1","0","12","0","2","5","0","paragraph"
"tions for new, unseen data. In the era of “big data”, a lot of data","0","0","0","1","3","15","0","0","5","0","paragraph"
"is available with all sorts of variables. The general assumption is","0","0","0","1","3","11","0","0","3","0","paragraph"
"that the more data is used, the more precise becomes the algo-","0","0","0","1","0","12","0","2","2","0","paragraph"
"rithm and its predictions. When using a large amount of data, it","0","0","0","1","3","12","0","1","5","0","paragraph"
"clearly contains many correlations. However, not all correlations","0","0","0","1","3","8","0","1","2","0","paragraph"
"imply causality, because no matter how large the dataset is, it","0","0","0","1","0","11","0","1","3","0","paragraph"
"still only remains a snapshot of reality.","0","0","0","1","0","7","0","1","2","0","paragraph"
"In a training data set on claims of a car insurance, red cars","0","0","1","0","3","13","0","1","4","0","paragraph"
"may have caused more accidents than cars of other colour.","0","0","1","1","0","10","0","2","3","0","paragraph"
"The ML algorithm detects this correlation. However, there is","0","0","1","1","3","9","0","1","2","0","paragraph"
"no scientific proof of causality between the colour of a car","0","0","1","1","0","11","0","0","4","0","paragraph"
"and the risk of accidents.","0","0","1","1","0","5","0","0","2","0","paragraph"
"Beyond the incomprehension in terms of pricing for a cus-","0","0","0","1","3","10","0","0","4","0","paragraph"
"tomer, for the sake of the algorithm’s performance it is crucial to","0","0","0","1","0","12","0","1","3","0","paragraph"
"notice and eliminate this kind of unwanted correlations. Other-","0","0","0","1","3","9","0","2","2","0","paragraph"
"wise, the algorithm is biased and results on new data in produc-","0","0","0","1","0","12","0","1","4","0","paragraph"
"tion may be poor. In the previous example, a competitor with a","0","0","0","1","3","12","0","1","2","0","paragraph"
"better algorithm, which does not falsely attribute a higher risk to","0","0","0","1","0","11","0","1","2","0","paragraph"
"drivers of red cars, can offer a lower price to those customers and","0","0","0","1","0","13","0","2","4","0","paragraph"
"entice them away.","0","0","0","1","0","3","0","1","1","0","paragraph"
"Besides the performance aspect, there is a second problem","0","0","0","1","3","9","0","0","2","0","paragraph"
"which appears when the predictions impact people, and when","0","0","0","1","0","9","0","2","2","0","paragraph"
"the algorithm is biased to favour privileged groups over unprivi-","0","0","0","1","0","10","0","1","3","0","paragraph"
"leged groups, this resulting in discrimination.","0","0","0","1","0","6","0","1","2","0","paragraph"
"3","1","0","1","1","2","1","1","0","0","1","paragraph"
"It is important to note that these unwanted discriminations","0","0","0","1","3","9","0","1","1","0","paragraph"
"may happen without explicitly providing sensitive personal","0","0","0","1","0","7","0","3","0","0","paragraph"
"data. In fact, other attributes can implicitly reveal this informa-","0","0","0","1","3","10","0","2","3","0","paragraph"
"tion serving as proxy. For example, a car model can hint at the","0","0","0","1","3","13","0","3","4","0","paragraph"
"owner’s sex, or the zip code may correlate with a resident’s race","0","0","0","1","0","12","0","2","4","0","paragraph"
"or religion. As of today, it is not clear how much a ML algorithm","0","0","0","1","3","14","0","0","3","0","paragraph"
"exploiting correlations can be seen as reconstructing a protected","0","0","0","1","0","9","0","5","1","0","paragraph"
"attribute and using it in a causal way.","0","0","0","1","0","8","0","2","2","0","paragraph"
"Although not everything is clear today, it is important to under-","0","0","0","1","3","11","0","0","2","0","paragraph"
"stand and to mitigate unwanted bias as much as possible, since","0","0","0","1","0","11","0","2","1","0","paragraph"
"it may not only result in low performance, but also cause unin-","0","0","0","1","0","12","0","3","2","0","paragraph"
"tended discrimination.","0","0","0","1","0","2","0","0","1","0","paragraph"
"In this report, we want to encourage all stakeholders to under-","0","0","0","1","3","11","0","2","4","0","paragraph"
"stand the most fundamental sources of unwanted bias and the","0","0","0","1","0","10","0","1","2","0","paragraph"
"consequences it causes. More precisely, we seek to explain to","0","0","0","1","3","10","0","3","3","0","paragraph"
"CDOs, DPOs, data scientists, actuaries, and any other interested","0","0","0","1","3","9","0","0","4","0","paragraph"
"parties how bias in data and in data models can be identified and","0","0","0","1","0","13","0","2","3","0","paragraph"
"mitigated.","0","0","0","1","0","1","0","1","0","0","paragraph"
"Marcin DETYNIECKI","1","1","0","1","2","2","0","0","1","0","paragraph"
"Chief Data Scientist","0","0","0","1","2","3","0","0","1","0","paragraph"
"4","1","0","1","1","2","1","1","0","0","1","paragraph"
"Table of Contents","1","1","1","1","2","3","0","0","2","0","heading"
"2. Introduction","1","1","1","0","2","2","0","0","1","1","heading"
"Machine learning models are increasingly used in decision","0","0","0","1","3","8","0","1","2","0","paragraph"
"making processes. In many fields of application, they gener-","0","0","0","1","3","9","0","1","4","0","paragraph"
"ally deliver superior performance compared with conven-","0","0","0","1","0","7","0","2","2","0","paragraph"
"tional, deterministic algorithms. However, those models","0","0","0","1","3","6","0","0","2","0","paragraph"
"are mostly black boxes which are hard, if not impossible,","0","0","0","1","0","10","0","0","1","0","paragraph"
"to interpret. Since many applications of machine learn-","0","0","0","1","3","8","0","1","2","0","paragraph"
"ing models have far-reaching consequences on people","0","0","0","1","0","7","0","1","3","0","paragraph"
"(credit approval, recidivism score etc.), there is grow-","0","0","0","1","0","8","0","0","0","0","paragraph"
"ing concern about their potential to reproduce discrim-","0","0","0","1","0","8","0","2","2","0","paragraph"
"ination against a particular group of people based on pro-","0","0","0","1","0","10","0","1","3","0","paragraph"
"tected characteristics such as gender, race, religion, or","0","0","0","1","0","8","0","0","4","0","paragraph"
"other. In particular, algorithms trained on biased data are","0","0","0","1","3","9","0","1","2","0","paragraph"
"prone to learn, perpetuate or even reinforce these biases","0","0","0","1","0","9","0","3","1","0","paragraph"
"[1]. In recent years, many incidents of this nature have","0","0","0","0","3","10","0","0","3","0","paragraph"
"been documented. For example, an algorithmic model","0","0","0","1","3","7","0","1","1","0","paragraph"
"used to generate predictions of criminal recidivism in","0","0","0","1","0","8","0","2","2","0","paragraph"
"the United States (COMPAS) discriminated against black","0","0","0","1","3","7","0","1","3","0","paragraph"
"defendants [2]. Also, discrimination based on gender and","0","0","0","0","3","8","0","1","3","1","paragraph"
"race could be demonstrated for targeted and automated","0","0","0","1","0","8","0","4","1","0","paragraph"
"online advertising on employment opportunities [3].","0","0","0","0","0","6","0","0","2","1","paragraph"
"In this context, the EU introduced the General Data","0","0","0","1","3","9","0","1","3","0","paragraph"
"Protection Regulation (GDPR) in May 2018. This legisla-","0","0","0","1","3","8","0","0","3","0","paragraph"
"tion represents one of the most important changes in","0","0","0","1","0","9","0","1","2","1","paragraph"
"the regulation of data privacy in more than 20 years. It","0","0","0","1","3","11","0","0","4","0","paragraph"
"strictly regulates the collection and use of protected per-","0","0","0","1","0","9","0","2","3","0","paragraph"
"sonal data. With the aim of obtaining non-discriminatory","0","0","0","1","3","8","0","1","2","0","paragraph"
"algorithms, it rules in Article 9(1): “Processing of personal","0","0","0","1","3","9","0","1","3","0","paragraph"
"data revealing racial or ethnic origin, political opinions,","0","0","0","1","0","8","0","1","3","0","paragraph"
"religious or philosophical beliefs, or trade union member-","0","0","0","1","0","8","0","0","2","0","paragraph"
"ship, and the processing of genetic data, biometric data for the","0","0","0","1","0","11","0","0","4","0","paragraph"
"purpose of uniquely identifying a natural person, data concern-","0","0","0","1","0","9","0","1","2","0","paragraph"
"ing health or data concerning a natural person’s sex life or sexual","0","0","0","1","0","12","0","2","4","0","paragraph"
"orientation shall be prohibited.” [4]","0","0","0","0","0","5","0","2","1","1","paragraph"
"Currently, one fairness method often used in practice is to","0","0","0","1","3","10","0","1","2","1","paragraph"
"remove protected attributes from the data set. This concept is","0","0","0","1","3","10","0","3","2","0","paragraph"
"known as “fairness through unawareness” [5]. While this approach","0","0","0","0","3","9","0","1","3","0","paragraph"
"may prove viable when using conventional, deterministic algo-","0","0","0","1","0","8","0","3","0","0","paragraph"
"rithms with a manageable quantity of data, it is insufficient for","0","0","0","1","0","11","0","0","3","0","paragraph"
"machine learning algorithms trained on “big data”. Here, com-","0","0","0","1","3","9","0","1","2","0","paragraph"
"plex correlations in the data may provide unexpected links to pro-","0","0","0","1","0","11","0","3","3","0","paragraph"
"tected information. This way, presumably non-protected attri-","0","0","0","1","3","7","0","0","2","0","paragraph"
"butes can serve as substitutes or proxies for protected attributes.","0","0","0","1","0","10","0","2","4","0","paragraph"
"For this reason, next to optimizing the performance of a","0","0","0","1","3","10","0","1","2","0","paragraph"
"machine learning model, the new challenge for data scientists is","0","0","0","1","0","10","0","0","3","0","paragraph"
"to determine whether the model output predictions are discrim-","0","0","0","1","0","9","0","1","1","0","paragraph"
"inatory, and how they can mitigate such unwanted bias as much","0","0","0","1","0","11","0","2","3","0","paragraph"
"as possible.","0","0","0","1","0","2","0","0","0","0","paragraph"
"3. Distinctive","1","1","1","0","2","2","0","0","0","1","heading"
"features of machine","1","1","1","1","0","3","0","0","2","0","heading"
"learning","1","1","1","1","0","1","0","0","1","0","heading"
"In order to understand the fundamental char-","0","0","0","1","3","7","0","1","2","0","paragraph"
"acteristic differences of machine learning (ML), which we believe","0","0","0","1","3","9","0","1","4","0","paragraph"
"correspond to a paradigm shift, we compare in this section the","0","0","0","1","0","11","0","2","3","0","paragraph"
"functioning of conventional algorithms with the new type of algo-","0","0","0","1","0","10","0","1","3","0","paragraph"
"rithms, ML. The two major interrelated differences are, first, a","0","0","0","1","3","10","0","1","2","1","paragraph"
"new type of relationship to data and, second, the nature of the","0","0","0","1","0","12","0","0","4","0","paragraph"
"algorithm used in the production phase (vs. development one).","0","0","0","1","0","9","0","1","3","0","paragraph"
"Through this prism, we propose to compare classical algorithms,","0","0","0","1","3","9","0","2","3","0","paragraph"
"which we call here deterministic algorithms (DA), with machine","0","0","0","1","3","9","0","1","3","0","paragraph"
"learning ones.","0","0","0","1","0","2","0","1","1","0","paragraph"
"Development","1","1","0","1","2","1","0","0","1","0","paragraph"
"Production","1","1","0","1","2","1","0","0","1","0","paragraph"
"????","0","0","1","1","2","1","0","0","0","0","paragraph"
"????","0","0","1","1","2","1","0","0","0","0","paragraph"
"Figure 1: Deterministic algorithm (DA) in development and production","0","0","0","0","3","9","0","0","5","1","paragraph"
"phase","0","0","0","1","0","1","0","0","1","0","paragraph"
"Deterministic algorithm (DA)","1","1","1","1","3","3","0","0","2","0","heading"
"Conventional algorithms usually are deterministic algorithms.","0","0","0","1","3","6","0","0","2","0","paragraph"
"Like a recipe, they consist of a hard-coded set of rules which","0","0","0","1","3","12","0","2","4","0","paragraph"
"always produce the same output. The software engineer explicitly","0","0","0","1","3","9","0","1","2","0","paragraph"
"programs the algorithm’s logic without using any data. When the","0","0","0","1","3","10","0","1","4","0","paragraph"
"algorithm is put into production, data are fed to the algorithm in","0","0","0","1","0","12","0","2","4","0","paragraph"
"order to produce results. Data has no impact on the algorithm in","0","0","0","1","3","12","0","1","5","0","paragraph"
"itself.","0","0","0","1","0","1","0","0","1","0","paragraph"
"11 11","1","0","1","0","2","2","0","0","0","1","paragraph"
"Development","1","1","0","1","2","1","0","0","1","0","paragraph"
"Figure 2: Machine","0","0","0","0","2","3","0","0","2","1","paragraph"
"production phase","0","0","0","1","0","2","0","0","1","0","paragraph"
"????","0","0","1","1","2","1","0","0","0","0","paragraph"
"Learning (ML)","0","0","0","1","2","2","0","1","0","0","paragraph"
"Machine learning (ML)","1","1","1","1","3","3","0","0","2","0","heading"
"Production","1","1","0","1","2","1","0","0","1","0","paragraph"
"????","0","0","1","1","2","1","0","0","0","0","paragraph"
"algorithm in development and","0","0","0","1","0","4","0","0","2","0","paragraph"
"In contrast to deterministic algorithms, when “programming”","0","0","0","1","3","7","0","0","2","0","paragraph"
"machine learning we have two different phases. The first one is","0","0","0","1","3","11","0","1","3","1","paragraph"
"programming the ML algorithm itself, which is de facto what we","0","0","0","1","3","11","0","1","4","0","paragraph"
"just described for the deterministic algorithms. In a second phase,","0","0","0","1","3","10","0","1","2","0","paragraph"
"usually called “training”, a data scientist (or data engineer) uses","0","0","0","1","0","10","0","2","2","0","paragraph"
"the ML algorithm together with data to produce a new algorithm:","0","0","0","1","3","11","0","1","3","0","paragraph"
"the production algorithm. Often, the ML algorithm and the","0","0","0","1","3","9","0","0","2","0","paragraph"
"production algorithm get confused. Data scientist call the latter","0","0","0","1","3","9","0","2","2","0","paragraph"
"a “trained algorithm” which contains thousands of parameters","0","0","0","1","0","8","0","2","3","1","paragraph"
"that were not explicitly programmed by a human, but rather","0","0","0","1","0","10","0","1","1","0","paragraph"
"automatically “learned”, i.e. estimated, using data samples. Here,","0","0","0","1","3","8","0","3","1","0","paragraph"
"data is grown into an algorithm.","0","0","0","0","0","6","0","1","2","0","paragraph"
"12","1","0","1","1","2","1","1","0","0","1","paragraph"
"ML algorithms are strongly dependent on the data they use to","0","0","0","1","3","11","0","1","3","0","paragraph"
"create the “production algorithm”. Because they are also prone","0","0","0","1","3","9","0","1","2","0","paragraph"
"to any hidden bias contained in the data, and due to the potential","0","0","0","1","0","13","0","2","3","0","paragraph"
"of getting deployed at scale, even minimal systematic errors in","0","0","0","1","0","10","0","2","2","0","paragraph"
"the algorithms can lead to reinforced discrimination.","0","0","0","1","0","7","0","3","2","0","paragraph"
"4. Different sources of bias","1","1","1","0","3","5","0","0","2","1","heading"
"There are plenty of different forms of bias which can cause","0","0","0","1","3","11","0","2","3","0","paragraph"
"unwanted and unexpected results [6] [7]. Automation bias for","0","0","0","0","3","9","0","0","2","1","paragraph"
"example is the phenomenon when people trust suggestions of","0","0","0","1","0","9","0","1","4","0","paragraph"
"automated systems over human reasoning. Several severe air-","0","0","0","1","3","8","0","1","2","0","paragraph"
"plane accidents happened in the past because the pilots had","0","0","0","1","0","10","0","1","3","0","paragraph"
"trusted the autopilot more than their own judgment [8]. Another","0","0","0","1","3","10","0","1","2","0","paragraph"
"type of bias may occur when an algorithm is deployed in an envi-","0","0","0","1","0","13","0","3","4","0","paragraph"
"ronment for which it was not trained in the first place. For exam-","0","0","0","1","3","13","0","1","3","0","paragraph"
"ple, if it is applied in a different geographical region or on a differ-","0","0","0","1","0","14","0","1","3","0","paragraph"
"ent group of people.","0","0","0","1","0","4","0","0","2","0","paragraph"
"While explicitly programmed rules in algorithms or the way","0","0","0","1","3","9","0","1","3","0","paragraph"
"they are used in practice may produce biased results, this is","0","0","0","1","0","11","0","3","3","0","paragraph"
"a long-known problem which already applies to conventional","0","0","0","1","0","8","0","2","1","0","paragraph"
"deterministic algorithms. In the following, we focus on a new","0","0","0","1","3","10","0","1","3","0","paragraph"
"source of bias resulting from data, which was introduced by the","0","0","0","1","0","11","0","2","3","0","paragraph"
"emergence of machine learning technologies. More specifically,","0","0","0","1","3","7","0","0","2","0","paragraph"
"we discuss human bias in data and selection bias.","0","0","0","1","0","9","0","1","3","0","paragraph"
"13","1","0","1","1","2","1","1","0","0","1","paragraph"
"4.1 Human bias","1","1","1","0","2","3","0","0","1","1","heading"
"The first source of bias which comes naturally to mind is","0","0","0","1","3","11","0","2","2","0","paragraph"
"human bias. Different types of this kind of well-studied bias are","0","0","0","1","3","11","0","1","4","0","paragraph"
"outlined in Table 1.","0","0","0","1","3","4","0","1","1","1","paragraph"
"Training data can consist of labels of objective observations,","0","0","0","1","3","9","0","3","3","0","paragraph"
"as for instance coming from a measuring device. However, train-","0","0","0","1","3","10","0","2","2","0","paragraph"
"ing data may also involve human assessment. Data labels which","0","0","0","1","3","10","0","2","3","0","paragraph"
"include human judgment may have been labelled with prejudice.","0","0","0","1","0","9","0","3","2","0","paragraph"
"Since the labels serve as ground truth, the algorithm’s perfor-","0","0","0","0","3","10","0","1","2","0","paragraph"
"mance directly depends on them, and any bias contained gets","0","0","0","1","0","10","0","3","3","0","paragraph"
"reproduced at scale in the model.","0","0","0","1","0","6","0","1","2","0","paragraph"
"Type","1","0","0","1","2","1","0","0","1","0","paragraph"
"In-group bias","0","0","0","1","2","2","0","0","1","0","paragraph"
"Out-group","0","0","0","1","2","1","0","0","1","0","paragraph"
"homogeneity bias","0","0","0","1","0","2","0","0","1","0","paragraph"
"Implicite bias","0","0","0","1","2","2","0","1","1","0","paragraph"
"Descripion","1","0","0","1","2","1","0","0","1","0","paragraph"
"Rather trust people","0","0","0","1","3","3","0","1","1","0","paragraph"
"of a group which you","0","0","0","1","0","5","0","0","1","0","paragraph"
"belong to.","0","0","0","1","0","2","0","1","0","0","paragraph"
"Less trust in people of","0","0","0","1","3","5","0","0","2","0","paragraph"
"a group which you do","0","0","0","1","0","5","0","0","2","0","paragraph"
"not belong to.","0","0","0","1","0","3","0","1","0","0","paragraph"
"False fundamental","0","0","0","1","3","2","0","0","0","0","paragraph"
"assumptions based on","0","0","0","1","0","3","0","1","1","0","paragraph"
"individual experience","0","0","0","1","0","2","0","0","1","0","paragraph"
"but not eligible for","0","0","0","1","0","4","0","0","0","0","paragraph"
"generalization.","0","0","0","1","0","1","0","0","1","0","paragraph"
"Example","1","0","0","1","2","1","0","0","1","0","paragraph"
"Preferring candidates","0","0","0","1","3","2","0","1","1","0","paragraph"
"in a recruitment","0","0","0","1","0","3","0","0","1","0","paragraph"
"process you share a","0","0","0","1","0","4","0","1","1","0","paragraph"
"biographical similarity","0","0","0","1","0","2","0","0","1","0","paragraph"
"with.","0","0","0","1","0","1","0","0","0","0","paragraph"
"Lack of language","0","0","0","1","3","3","0","0","2","0","paragraph"
"abilities may cause","0","0","0","1","0","3","0","2","1","0","paragraph"
"mistrust.","0","0","0","1","0","1","0","0","1","0","paragraph"
"Online streaming","0","0","0","1","3","2","0","0","1","0","paragraph"
"providers which tend","0","0","0","1","0","3","0","1","1","0","paragraph"
"to recommend movies","0","0","0","1","0","3","0","1","1","0","paragraph"
"about pink princesses","0","0","0","1","0","3","0","0","1","0","paragraph"
"to girls and movies","0","0","0","1","0","4","0","0","2","0","paragraph"
"about martial action","0","0","0","1","0","3","0","0","1","0","paragraph"
"heroes to boys.","0","0","0","1","0","3","0","0","2","0","paragraph"
"Table 1: List of different sources of human bias","0","0","0","0","3","9","0","0","4","1","paragraph"
"14","1","0","1","1","2","1","1","0","0","1","paragraph"
"4.2 Selection bias","1","1","1","0","2","3","0","0","1","1","heading"
"Another, less obvious source of bias is the process of how the","0","0","0","1","3","12","0","0","3","0","paragraph"
"data was collected. If data does not reflect the real distribution, a","0","0","0","1","3","12","0","2","3","0","paragraph"
"ML algorithm using these data for training will learn and enforce","0","0","0","1","3","11","0","4","3","0","paragraph"
"the bias.","0","0","0","1","0","2","0","0","1","0","paragraph"
"In Table 2 we provide a list of different types of bias which may","0","0","0","1","3","14","0","2","5","1","paragraph"
"cause selection bias in data.","0","0","0","1","0","5","0","0","2","0","paragraph"
"Type Descripion","1","0","0","1","2","2","0","0","1","0","paragraph"
"Data not selected","0","0","0","1","3","3","0","1","1","0","paragraph"
"Coverage bias in a representative","0","0","0","1","3","5","0","0","2","0","paragraph"
"manner.","0","0","0","1","0","1","0","0","1","0","paragraph"
"The frequency of","0","0","0","1","3","3","0","0","1","0","paragraph"
"events captured in","0","0","0","1","0","3","0","1","1","0","paragraph"
"the data does not","0","0","0","1","0","4","0","0","1","0","paragraph"
"correspond to the","0","0","0","1","0","3","0","1","0","0","paragraph"
"frequency in reality.","0","0","0","1","0","3","0","0","2","0","paragraph"
"Reporting bias This may happen","0","0","0","1","3","5","0","2","2","0","paragraph"
"when only extreme","0","0","0","1","0","3","0","0","0","0","paragraph"
"occurrences get","0","0","0","1","0","2","0","1","1","0","paragraph"
"registered while less","0","0","0","1","0","3","0","1","0","0","paragraph"
"outstanding events","0","0","0","1","0","2","0","0","1","0","paragraph"
"are omitted.","0","0","0","1","0","2","0","1","0","0","paragraph"
"Example","1","0","0","1","2","1","0","0","1","0","paragraph"
"Surveys conducted only on","0","0","0","1","3","4","0","1","1","0","paragraph"
"the Internet do not include","0","0","0","1","3","5","0","1","1","0","paragraph"
"households without","0","0","0","1","0","2","0","0","1","0","paragraph"
"Internet access.","0","0","0","1","3","2","0","0","1","0","paragraph"
"Movie, hotel or book","0","0","0","1","3","4","0","0","3","0","paragraph"
"reviews tend to be subject","0","0","0","1","0","5","0","1","1","0","paragraph"
"to reporting bias because","0","0","0","1","0","4","0","1","1","0","paragraph"
"only customers with","0","0","0","1","0","3","0","0","1","0","paragraph"
"extreme sentiments care","0","0","0","1","0","3","0","1","1","0","paragraph"
"to write a review.","0","0","0","1","0","4","0","1","1","0","paragraph"
"15 15","1","0","1","1","2","2","0","0","0","1","paragraph"
"Type","1","0","0","1","2","1","0","0","1","0","paragraph"
"Participation bias","0","0","0","1","2","2","0","0","1","0","paragraph"
"Sampling bias","0","0","0","1","2","2","0","1","1","0","paragraph"
"Descripion","1","0","0","1","2","1","0","0","1","0","paragraph"
"Some demographics","0","0","0","1","3","2","0","0","1","0","paragraph"
"may be","0","0","0","1","0","2","0","1","0","0","paragraph"
"underrepresented in","0","0","0","1","0","2","0","0","0","0","paragraph"
"the data.","0","0","0","1","0","2","0","0","1","0","paragraph"
"Using a non-","0","0","0","1","2","3","0","1","1","0","paragraph"
"randomized sub","0","0","0","1","0","2","0","0","1","0","paragraph"
"sample for model","0","0","0","1","0","3","0","0","2","0","paragraph"
"training can make it","0","0","0","1","0","4","0","2","2","0","paragraph"
"susceptible to bias.","0","0","0","1","0","3","0","0","1","0","paragraph"
"Example","1","0","0","1","2","1","0","0","1","0","paragraph"
"Busy parents with young","0","0","0","1","3","4","0","0","1","0","paragraph"
"children are more likely to","0","0","0","1","0","5","0","0","1","0","paragraph"
"refuse a telephone survey","0","0","0","1","0","4","0","1","1","0","paragraph"
"than retired people with","0","0","0","1","0","4","0","1","1","0","paragraph"
"plenty of time.","0","0","0","1","0","3","0","0","2","0","paragraph"
"Data from telephone","0","0","0","1","3","3","0","0","2","0","paragraph"
"surveys conducted on a","0","0","0","1","0","4","0","1","1","0","paragraph"
"working day between 10","0","0","0","1","0","4","0","1","1","0","paragraph"
"and 11 a.m. may over-","0","0","0","1","0","5","0","0","1","0","paragraph"
"represent the non-working","0","0","0","1","0","3","0","1","0","0","paragraph"
"population.","0","0","0","1","0","1","0","0","1","0","paragraph"
"Table 2: List of different sources of selection bias","0","0","0","0","3","9","0","0","4","1","paragraph"
"16","1","0","1","1","2","1","1","0","0","1","paragraph"
"5. What is fair?","1","1","1","0","3","4","0","0","1","1","heading"
"Fairness is an ethical concept which refers to plural concep-","0","0","0","1","3","10","0","1","2","0","paragraph"
"tions of justice between individuals. This concept is at the heart","0","0","0","1","3","11","0","0","5","0","paragraph"
"of social science research, and the difficulty to find a general defi-","0","0","0","1","0","12","0","1","3","0","paragraph"
"nition is obvious: fairness is based on ethical value judgment, and","0","0","0","1","0","11","0","1","3","0","paragraph"
"its application will vary according to cultures, religions, political","0","0","0","1","0","9","0","3","3","0","paragraph"
"systems, etc.","0","0","0","1","0","2","0","0","1","0","paragraph"
"In order to be able to measure and improve fairness in techni-","0","0","0","1","3","12","0","2","3","0","paragraph"
"cal systems, we would first have to agree on a statistical defini-","0","0","0","1","0","12","0","2","2","0","paragraph"
"tion of fairness as baseline. In current research, there exist plenty","0","0","0","1","3","11","0","1","5","0","paragraph"
"of different definitions which are mutually incompatible [29]. In the","0","0","0","0","3","10","0","0","1","0","paragraph"
"following, we outline the most popular approaches. No definition","0","0","0","1","3","9","0","2","3","0","paragraph"
"serves as silver bullet for all use cases, the right choice depends","0","0","0","1","0","12","0","2","3","0","paragraph"
"on the context of the use case and on the data available.","0","0","0","1","0","12","0","0","3","0","paragraph"
"17","1","0","1","1","2","1","1","0","0","1","paragraph"
"5.1 Information sanitization","1","1","1","0","3","3","0","0","1","1","heading"
"This approach limits the data that are used for training the","0","0","0","1","3","11","0","3","2","0","paragraph"
"classifier. In its most straightforward version named “Fairness","0","0","0","1","3","8","0","1","2","0","paragraph"
"through unawareness”, an algorithm is considered fair if it does","0","0","0","1","0","10","0","1","3","0","paragraph"
"not make use of the protected attribute [5]. The notion is that","0","0","0","0","3","12","0","2","3","0","paragraph"
"omission of protected attributes when training the model pre-","0","0","0","1","0","9","0","2","3","0","paragraph"
"vents from unfair use.","0","0","0","1","0","4","0","0","2","0","paragraph"
"5.2 Statistical/Group fairness","1","1","1","0","3","3","0","0","1","1","heading"
"This type of fairness definition partitions the world into","0","0","0","1","3","9","0","1","2","0","paragraph"
"groups defined by one or several high-level protected attributes.","0","0","0","1","0","9","0","2","2","1","paragraph"
"It requires that a specific relevant statistic about the classifier is","0","0","0","1","3","11","0","1","3","0","paragraph"
"equal across those groups.","0","0","0","1","0","4","0","1","1","0","paragraph"
"5.2.1 Demographic parity","1","0","1","0","3","3","0","0","1","1","heading"
"An algorithm is considered fair if the prediction is independent","0","0","0","1","3","10","0","1","2","0","paragraph"
"of the protected attribute [9]. If the base ground truth outcome","0","0","0","0","3","11","0","1","2","1","paragraph"
"of the two demographic groups are totally different, this defini-","0","0","0","1","0","10","0","0","1","1","paragraph"
"tion might not be appropriate, since for example a model which","0","0","0","1","0","11","0","1","3","0","paragraph"
"selects the best 5% women and randomly 5% of men would be","0","0","0","1","0","12","0","2","3","0","paragraph"
"perfectly fair according to this definition.","0","0","0","1","0","6","0","1","1","0","paragraph"
"5.2.2 Equalized odds","1","0","1","0","2","3","0","0","1","1","heading"
"An algorithm is considered fair if across both demographics for","0","0","0","1","3","10","0","1","2","0","paragraph"
"the positive outcome the predictor has equal true positive rates,","0","0","0","1","0","10","0","0","3","0","paragraph"
"and for negative outcomes, the predictor has equal false positive","0","0","0","1","0","10","0","0","2","0","paragraph"
"rates [10]. This constraint enforces that accuracy is equally high in","0","0","0","0","3","11","0","0","3","0","paragraph"
"all demographics. The rate of positive and negative classification","0","0","0","1","3","9","0","0","3","0","paragraph"
"is equal across the groups.","0","0","0","1","0","5","0","0","1","0","paragraph"
"18","1","0","1","1","2","1","1","0","0","1","paragraph"
"5.2.3 Equalized opportunities","1","0","1","0","3","3","0","0","1","1","heading"
"An algorithm is considered fair if across both demographics,","0","0","0","1","3","9","0","1","2","0","paragraph"
"only for the positive outcome the predictor of has equal true pos-","0","0","0","1","0","12","0","0","2","0","paragraph"
"itive rates [10]. The notion is that the chances of being correctly","0","0","0","0","3","12","0","0","2","0","paragraph"
"classified positive should be equal for every group.","0","0","0","1","0","8","0","1","1","0","paragraph"
"5.3 Individual fairness","1","1","1","0","3","3","0","0","1","1","heading"
"This family of definitions binds at the individual level. It sug-","0","0","0","1","3","11","0","0","4","0","paragraph"
"gests that fairness means that similar individuals should be","0","0","0","1","0","9","0","2","3","0","paragraph"
"treated similarly, specifying an adequate similarity metric.","0","0","0","1","0","7","0","2","1","0","paragraph"
"5.3.1 Fairness through awareness","1","0","1","0","3","4","0","0","2","1","heading"
"An algorithm is considered fair if it gives similar predictions to","0","0","0","1","3","11","0","2","3","0","paragraph"
"similar individuals [9].","0","0","0","0","0","3","0","0","1","1","paragraph"
"5.3.2 Calibration","1","0","1","0","2","2","0","0","1","0","heading"
"The positive predictive value is equalized across the groups for","0","0","0","1","3","10","0","1","2","0","paragraph"
"a score [11]. For any demographic, an optimally calibrated classi-","0","0","0","0","3","10","0","1","2","1","paragraph"
"fier tries to match the percentage of individuals with a specific","0","0","0","1","0","11","0","2","4","0","paragraph"
"score with the probability score.","0","0","0","1","0","5","0","1","1","0","paragraph"
"19","1","0","1","1","2","1","1","0","0","1","paragraph"
"6. Bias mitigation","1","1","1","0","3","3","0","0","1","1","heading"
"Many bias mitigation strategies for machine learning have","0","0","0","1","3","8","0","0","2","0","paragraph"
"been proposed in recent years. The different approaches can be","0","0","0","1","3","10","0","2","2","0","paragraph"
"divided in the following three distinct groups.","0","0","0","1","0","7","0","2","1","1","paragraph"
"6.1 Pre-processing","1","1","1","0","2","2","0","0","1","1","heading"
"Efficient bias mitigation starts at the data acquisition and pro-","0","0","0","1","3","10","0","1","2","0","paragraph"
"cessing phase since the source of the data and also the extraction","0","0","0","1","0","12","0","1","4","0","paragraph"
"methods can introduce unwanted bias. Therefore, a maximum of","0","0","0","1","3","9","0","2","2","0","paragraph"
"effort must be put into validating the integrity of the data source","0","0","0","1","0","12","0","3","3","0","paragraph"
"and in ensuring that the data collection process includes appro-","0","0","0","1","0","10","0","2","2","0","paragraph"
"priate and reliable methods of measurement. Prior to the era","0","0","0","1","3","10","0","0","3","0","paragraph"
"of “big data”, most data were collected by questionnaires. This","0","0","0","1","3","10","0","1","3","0","paragraph"
"allowed the development of experimental designs to control pos-","0","0","0","1","0","9","0","2","3","0","paragraph"
"sible biases by statistical analysis. Today, technology provides","0","0","0","1","3","8","0","1","3","0","paragraph"
"us with large amounts of data at low cost, however, information","0","0","0","1","0","11","0","0","4","0","paragraph"
"about the conditions under which the data were collected is often","0","0","0","1","0","11","0","1","2","0","paragraph"
"rare.","0","0","0","1","0","1","0","0","0","0","paragraph"
"Hence, algorithms which belong to the pre-processing fam-","0","0","0","1","3","8","0","1","2","0","paragraph"
"ily ensure that the input data is balanced and fair. This can be","0","0","0","1","3","13","0","2","1","0","paragraph"
"achieved by suppressing the protected attributes, by changing","0","0","0","1","0","8","0","4","1","0","paragraph"
"class labels of the data set, and by reweighting or resampling the","0","0","0","1","0","12","0","2","2","0","paragraph"
"data [13] [14] [15]. In some cases, it is also necessary to reconstruct","0","0","0","0","3","13","0","1","3","3","paragraph"
"omitted or censored data in order to ensure the data sample is","0","0","0","1","0","12","0","3","3","0","paragraph"
"representative. There exist plenty of imputation methods to","0","0","0","1","3","8","0","1","3","0","paragraph"
"achieve this objective, and the hot deck procedures belong to the","0","0","0","1","0","11","0","2","2","0","paragraph"
"most efficient ones [14].","0","0","0","0","0","4","0","0","1","1","paragraph"
"20","1","0","1","1","2","1","1","0","0","1","paragraph"
"6.2 In-processing","1","1","1","0","2","2","0","0","1","1","heading"
"The second type of mitigation strategies comprises the in-pro-","0","0","0","1","3","9","0","1","3","0","paragraph"
"cessing algorithms. Here, undesired bias is directly mitigated","0","0","0","1","3","8","0","2","2","0","paragraph"
"during the training phase. A straightforward approach to achieve","0","0","0","1","3","9","0","1","2","0","paragraph"
"this goal is to integrate a fairness penalty directly in the loss func-","0","0","0","1","0","13","0","1","3","0","paragraph"
"tion. One such algorithm integrates a decision boundary covari-","0","0","0","1","3","9","0","1","2","1","paragraph"
"ance constraint for logistic regression or linear SVM [13]. In another","0","0","0","0","3","11","0","0","4","0","paragraph"
"approach, a meta algorithm takes a fairness metric as part of the","0","0","0","1","0","12","0","1","2","0","paragraph"
"input and returns a new classifier optimized towards that fairness","0","0","0","1","0","10","0","2","3","0","paragraph"
"metric [9]. Furthermore, the emergence of generative adversar-","0","0","0","0","3","8","0","0","2","0","paragraph"
"ial networks (GANs) provided the required underpinning for fair","0","0","0","1","3","9","0","2","3","0","paragraph"
"classification using adversarial debiasing [17]. In this field, a neural","0","0","0","0","3","10","0","1","3","1","paragraph"
"network classifier is trained as classical predictor, while simulta-","0","0","0","1","0","9","0","1","2","0","paragraph"
"neously the ability of an adversarial neural network to predict a","0","0","0","1","0","11","0","1","2","0","paragraph"
"protected attribute is minimized [18] [19] [20].","0","0","0","0","0","7","0","2","1","3","paragraph"
"21","1","0","1","1","2","1","1","0","0","1","paragraph"
"6.3 Post-processing","1","1","1","0","2","2","0","1","0","1","heading"
"The final group of mitigation algorithms follows a post-pro-","0","0","0","1","3","9","0","1","3","0","paragraph"
"cessing approach. In this case, only the output of a trained classi-","0","0","0","1","3","12","0","2","3","0","paragraph"
"fier is modified. A Bayes optimal equalized odds predictor can be","0","0","0","1","3","11","0","2","2","0","paragraph"
"used to change output labels with respect to an equalized odds","0","0","0","1","0","11","0","2","3","0","paragraph"
"objective [11]. A different paper presents a weighted estimator for","0","0","0","0","3","10","0","1","2","0","paragraph"
"demographic disparity which uses soft classification based on","0","0","0","1","0","8","0","2","2","0","paragraph"
"proxy model outputs [21]. The advantage of post-processing algo-","0","0","0","0","3","9","0","0","2","1","paragraph"
"rithms is that fair classifiers are derived without the necessity of","0","0","0","1","0","11","0","1","3","0","paragraph"
"retraining the original model which may be time consuming or","0","0","0","1","0","10","0","3","1","0","paragraph"
"difficult to implement in production environments. However, this","0","0","0","1","3","8","0","1","1","0","paragraph"
"approach may have a negative effect on accuracy or could com-","0","0","0","1","0","11","0","2","3","0","paragraph"
"promise any generalization acquired by the original classifier [22].","0","0","0","0","0","9","0","2","2","1","paragraph"
"22","1","0","1","1","2","1","1","0","0","1","paragraph"
"7. Legal context1","1","1","1","0","3","3","0","0","1","1","heading"
"In most situations, personal data will be used to train the ML","0","0","0","1","3","12","0","3","3","0","paragraph"
"algorithm. These data are subject of a special protection, at Euro-","0","0","0","1","3","11","0","0","4","0","paragraph"
"pean level, mainly by the General Data Protection Regulation","0","0","0","1","3","9","0","0","2","0","paragraph"
"(GDPR). The purpose of this regulation, which entered into force","0","0","0","1","3","10","0","1","4","0","paragraph"
"on 25th May 2018, is to harmonize at European level the condi-","0","0","0","1","3","12","0","1","3","0","paragraph"
"tions for the processing of personal data and their use, particu-","0","0","0","1","0","11","0","0","4","0","paragraph"
"larly for decision-making. In the following, we provide details on","0","0","0","1","3","10","0","1","4","0","paragraph"
"the existing rules of present regulation in the context of fairness","0","0","0","1","0","11","0","1","4","0","paragraph"
"and bias. Further, we open the discussion by presenting limita-","0","0","0","1","3","10","0","2","4","0","paragraph"
"tions and gaps we identified with respect to the emergence of","0","0","0","1","0","11","0","1","5","0","paragraph"
"machine learning technologies.","0","0","0","1","0","3","0","0","1","0","paragraph"
"7.1 State-of-the-art","1","1","1","0","2","2","0","0","2","1","heading"
"At European level, several texts regulate the use of informa-","0","0","0","1","3","10","0","1","4","0","paragraph"
"tion on people in order to fight discrimination. This principle is","0","0","0","1","3","11","0","1","5","0","paragraph"
"stated in the Convention for the Protection of Human Rights and","0","0","0","1","3","11","0","1","3","0","paragraph"
"Fundamental Freedoms [23] in article 14 entitled “Prohibition of","0","0","0","0","3","9","0","1","2","1","paragraph"
"discrimination”. It is also contained in the Charter of Fundamen-","0","0","0","1","3","10","0","1","3","0","paragraph"
"tal Rights of the European Union [24] which states in Article 21","0","0","0","0","3","12","0","1","3","1","paragraph"
"that “[a]ny discrimination based on any ground such as sex, race,","0","0","0","1","0","11","0","1","3","0","paragraph"
"colour, ethnic or social origin, genetic features, language, religion","0","0","0","1","0","9","0","0","4","0","paragraph"
"or belief, political or any other opinion, membership of a national","0","0","0","1","0","11","0","0","2","0","paragraph"
"minority, property, birth,","0","0","0","1","0","3","0","0","3","0","paragraph"
"shall be prohibited.”","0","0","0","1","0","3","0","2","0","0","paragraph"
"disability, age or sexual orientation","0","0","0","1","0","5","0","0","3","0","paragraph"
"These articles materialize the fact that society, via this regu-","0","0","0","1","3","10","0","1","2","0","paragraph"
"lation, expects that whatever is necessary will be done to avoid","0","0","0","1","0","11","0","4","1","0","paragraph"
"1 B. Ruf, M. Hirot, M. Detyniecki and N. Shire, “Regulating","0","0","0","1","3","11","0","0","5","0","paragraph"
"Machine Learning: where do we stand?”, AXA, 2019.","0","0","0","1","3","8","0","1","2","0","paragraph"
"23","1","0","1","1","2","1","1","0","0","1","paragraph"
"any type of discrimination. Regulation goes one level further and","0","0","0","1","3","10","0","1","3","1","paragraph"
"gives some advice on how this could be achieved by proposing","0","0","0","1","0","11","0","4","1","0","paragraph"
"to forbid the use or the consideration of some type of data. For","0","0","0","1","3","13","0","1","4","0","paragraph"
"instance, in the field of insurance and financial services, it is for-","0","0","0","1","0","12","0","0","4","0","paragraph"
"bidden to use sex as a factor in the calculation of premiums and","0","0","0","1","0","13","0","1","4","0","paragraph"
"benefits if it results in differences in individuals’ premiums and","0","0","0","1","0","10","0","1","4","0","paragraph"
"benefits [25].","0","0","0","0","0","2","0","0","1","1","paragraph"
"As a general principle, the GDPR prohibits the use of data which","0","0","0","1","3","12","0","1","4","0","paragraph"
"are considered protected and subject to special protection. For","0","0","0","1","3","9","0","2","1","0","paragraph"
"instance, data concerning health, a natural person’s sex life, or","0","0","0","1","0","10","0","1","5","0","paragraph"
"sexual orientation (Art. 9) and data related to criminal convic-","0","0","0","1","3","10","0","1","3","1","paragraph"
"tions and offences (Art. 10) can only be processed under certain","0","0","0","1","3","11","0","2","2","1","paragraph"
"conditions (for example requiring consent of the data subject).","0","0","0","1","0","9","0","1","4","0","paragraph"
"A processing for profiling may reveal some inferred protected","0","0","0","1","3","9","0","4","2","0","paragraph"
"data from correlations. In this case, the WP29 [23] recommends","0","0","0","1","3","10","0","1","3","1","paragraph"
"checking that:","0","0","0","1","0","2","0","1","0","0","paragraph"
"9 the processing","0","0","0","0","0","3","0","0","1","1","paragraph"
"purpose;","0","0","0","1","0","1","0","0","1","0","paragraph"
"is not incompatible with the original","0","0","0","1","0","6","0","0","0","0","paragraph"
"9 they have identified a lawful basis for the processing of","0","0","0","0","0","11","0","1","3","1","paragraph"
"the special category data; and","0","0","0","1","0","5","0","0","1","0","paragraph"
"9 they inform the data subject about the processing.","0","0","0","0","0","9","0","1","3","1","paragraph"
"It is also important to note that in certain sectors, such as","0","0","0","1","3","12","0","1","2","0","paragraph"
"insurance law, specific rules exist that allow people’s character-","0","0","0","1","0","9","0","2","3","0","paragraph"
"istics, such as age or health status, to be considered in order to","0","0","0","1","0","13","0","1","4","0","paragraph"
"offer them different products or services and therefore to pro-","0","0","0","1","0","10","0","1","3","0","paragraph"
"cess protected data.","0","0","0","1","0","3","0","1","2","0","paragraph"
"For instance, in France, the regulation of life insurance allows","0","0","0","1","3","10","0","1","4","0","paragraph"
"the insurer to ask the subscriber to complete a medical question-","0","0","0","1","0","11","0","2","3","0","paragraph"
"naire [27] that will determine if the insurer assures without special","0","0","0","0","0","11","0","3","2","1","paragraph"
"conditions, with exclusions, with a surcharge or even refuses to","0","0","0","1","0","10","0","1","3","0","paragraph"
"insure.","0","0","0","1","0","1","0","1","0","0","paragraph"
"24","1","0","1","1","2","1","1","0","0","1","paragraph"
"The French supervisory authority (Commission Nationale de","0","0","0","1","3","7","0","0","2","0","paragraph"
"dedicated to the insurance sector [14], which determine for each","0","0","0","1","0","10","0","2","1","1","paragraph"
"purpose which data can be collected and processed. These stan-","0","0","0","1","3","10","0","3","2","0","paragraph"
"subscription","0","0","0","1","0","1","0","0","1","0","paragraph"
"needed to assess risk or harm. Even though these simplified stan-","0","0","0","1","3","11","0","3","3","0","paragraph"
"dards are no longer in effect with the entry into force of GDPR,","0","0","0","1","3","13","0","0","5","0","paragraph"
"they","0","0","0","1","0","1","0","0","1","0","paragraph"
"7.2 Discussion","1","1","1","0","2","2","0","0","1","0","heading"
"The idea of preventing algorithms from unfair use of protected","0","0","0","1","3","10","0","2","3","0","paragraph"
"attributes by forbidding to use them in the training process is","0","0","0","1","0","11","0","2","3","0","paragraph"
"also known as “fairness through unawareness” [26]. However, it","0","0","0","0","3","9","0","1","3","1","paragraph"
"falls short in the case of “big data” where other attributes or a","0","0","0","1","0","13","0","1","2","0","paragraph"
"complex combination of them may serve as proxy of a protected","0","0","0","1","0","11","0","3","3","0","paragraph"
"attribute. Seemingly insignificant attributes, or several attri-","0","0","0","1","3","7","0","1","1","0","paragraph"
"butes combined, may provide an unexpected link to protected","0","0","0","1","0","9","0","4","2","0","paragraph"
"information.","0","0","0","1","0","1","0","0","1","0","paragraph"
"This risk is not totally solved but mitigated by the principle of","0","0","0","1","3","12","0","2","2","0","paragraph"
"data minimization according to which the data controller must","0","0","0","1","0","9","0","2","2","0","paragraph"
"collect and process only the personal data necessary for the","0","0","0","1","0","10","0","2","1","0","paragraph"
"intended purpose. By limiting the number of variables used, we","0","0","0","1","3","10","0","3","3","0","paragraph"
"theoretically limit the risks of finding proxies of a protected attri-","0","0","0","1","0","11","0","3","3","0","paragraph"
"bute. But market evolution and usage of new data, seeking for a","0","0","0","1","3","12","0","1","4","0","paragraph"
"more direct grasp of the risk, such as the one coming from con-","0","0","0","1","0","13","0","1","4","1","paragraph"
"nected objects (e.g. cars, home), will reveal the above-mentioned","0","0","0","1","0","9","0","4","3","0","paragraph"
"challenge.","0","0","0","1","0","1","0","0","1","0","paragraph"
"Moreover, paradoxically, by forbidding to collect protected","0","0","0","1","3","7","0","3","0","0","paragraph"
"attributes, there is no possibility to measure for potential dis-","0","0","0","1","0","10","0","1","1","0","paragraph"
"crimination at a later point, which may even impede the pursuit","0","0","0","1","0","11","0","2","3","0","paragraph"
"of fairness.","0","0","0","1","0","2","0","0","1","0","paragraph"
"25","1","0","1","1","2","1","1","0","0","1","paragraph"
"8. Recommendations","1","1","1","0","2","2","0","0","1","1","heading"
"In order to avoid negative impact from bias, such as low per-","0","0","0","1","3","12","0","1","3","0","paragraph"
"formance or unintended discrimination, it is absolutely neces-","0","0","0","1","0","8","0","0","3","0","paragraph"
"sary to minimize it. We have identified a few suggestions to tackle","0","0","0","1","3","12","0","3","3","0","paragraph"
"this challenge as of today.","0","0","0","1","0","5","0","0","2","0","paragraph"
"9 Raise awareness and train stakeholders","0","0","0","0","3","6","0","1","2","1","paragraph"
"Human bias is a major source of bias in AI. Therefore, we","0","0","1","1","3","12","0","0","5","0","paragraph"
"recommend producing educational material and conduc-","0","0","1","1","0","6","0","2","1","0","paragraph"
"ting workshops and trainings adapted to different levels for","0","0","1","1","0","9","0","1","4","0","paragraph"
"employees. Creating spaces for interdisciplinary exchange","0","0","1","1","3","6","0","1","3","0","paragraph"
"drives the comprehension of the topic and leads also to less","0","0","1","1","0","11","0","2","2","0","paragraph"
"biased products or results..","0","0","1","1","0","4","0","0","2","0","paragraph"
"9 Identify context-specific fairness definition","0","0","0","0","3","5","0","1","1","1","paragraph"
"To monitor and control bias, it is key to quantify fairness. Hence,","0","0","1","1","3","12","0","3","3","0","paragraph"
"for each application case, it is necessary to select the protected","0","0","1","1","0","11","0","2","2","0","paragraph"
"groups, decide on the best definition of fairness and identify a","0","0","1","1","0","11","0","2","3","0","paragraph"
"set of suitable metrics.","0","0","1","1","0","4","0","0","2","0","paragraph"
"9 Audit new products and monitor models in production","0","0","0","0","3","9","0","1","3","1","paragraph"
"We need to detect and mitigate bias continuously. Open source","0","0","1","1","3","10","0","4","3","0","paragraph"
"libraries such as “AI Fairness 360” [28] should become an inte-","0","0","1","1","3","11","0","2","1","1","paragraph"
"gral part of our development workflow. However, not all tes-","0","0","1","1","3","10","0","0","2","0","paragraph"
"ting can be automated. Establishing operational procedures","0","0","1","1","3","7","0","3","2","0","paragraph"
"and practices can help to avoid unwanted bias systematically.","0","0","1","1","0","9","0","3","2","0","paragraph"
"9 Produce knowledge and share","0","0","0","0","3","5","0","1","2","1","paragraph"
"The topic is complex, and the last months have given rise to","0","0","1","1","3","12","0","1","3","0","paragraph"
"significant public attention and debate. Therefore we believe","0","0","1","1","3","8","0","1","3","0","paragraph"
"that research effort is necessary. At AXA we have an inter-","0","0","1","1","3","11","0","0","3","0","paragraph"
"nal team of experts who follow the latest developments and","0","0","1","1","0","10","0","1","4","0","paragraph"
"actively contribute together with the academic community.","0","0","1","1","0","7","0","1","1","0","paragraph"
"The generated knowledge should also be shared with regula-","0","0","1","1","3","9","0","3","1","0","paragraph"
"tors in order to push for stable and clear legal framework.","0","0","1","1","0","11","0","1","3","0","paragraph"
"26","1","0","1","1","2","1","1","0","0","1","paragraph"
"9. Acknowledgements","1","1","1","0","2","2","0","0","1","1","heading"
"Big thanks to Marie Hirot, Data Protection Specialist at AXA, who","0","0","0","1","3","11","0","0","4","0","paragraph"
"provided the legal assessment of how bias is covered in current reg-","0","0","0","1","0","12","0","2","3","0","paragraph"
"ulation (Section 7).","0","0","1","0","3","3","0","0","2","0","paragraph"
"27","1","0","1","1","2","1","1","0","0","1","paragraph"
"10. Bibliography","1","1","1","0","2","2","0","0","1","1","heading"
"[1] T. Bolukbasi, K.-W. Chang, J. Zou, V. Saligrama and A.","0","0","0","1","3","11","0","0","5","1","paragraph"
"Kalai, “Man is to Computer Programmer as Woman is to","0","0","0","1","2","10","0","0","4","0","paragraph"
"Homemaker?","0","0","0","1","2","1","0","0","1","0","paragraph"
"1--25, 2016.","0","0","0","1","2","2","0","0","1","1","paragraph"
"Debiasing Word Embeddings,” CoRR, pp.","0","0","0","1","2","5","0","0","3","0","paragraph"
"[2] J. Angwin, J. Larson, S. Mattu and L. Kirchner, “Machine","0","0","0","1","3","11","0","0","5","1","paragraph"
"Bias. There’s software used across the country to predict","0","0","0","1","3","9","0","3","3","0","paragraph"
"future criminals. And it’s biased against blacks.,” 23 5 2016.","0","0","0","1","3","10","0","2","3","0","paragraph"
"[Online]. Available: https://www.propublica.org/article/","0","0","0","1","3","3","0","0","1","0","paragraph"
"machine-bias-risk-assessments-in-criminal-sentencing.","0","0","0","1","0","1","0","0","2","0","paragraph"
"[3] A. Lambrecht and C. Tucker, “Algorithmic Bias? An Empir-","0","0","0","1","3","10","0","0","3","1","paragraph"
"ical Study into Apparent Gender-Based Discrimination in","0","0","0","1","2","7","0","1","2","0","paragraph"
"the Display of STEM Career Ads,” SSRN Electronic Journal,","0","0","0","1","2","9","0","0","3","0","paragraph"
"2016.","0","0","0","1","2","1","0","0","0","0","paragraph"
"[4] European Union, “Regulation (EU) 2016/679 of the Euro-","0","0","0","1","3","9","0","0","3","1","paragraph"
"pean Parliament and of the Council of 27 April 2016 on the","0","0","0","1","2","12","0","0","3","0","paragraph"
"protection of natural persons with regard to the process-","0","0","0","1","0","9","0","0","4","0","paragraph"
"ing of personal data and on the free movement of such","0","0","0","1","0","11","0","0","3","0","paragraph"
"data, and repealing Directive 95/46/EC,” Official Journal","0","0","0","1","3","7","0","1","3","0","paragraph"
"of the European Union, pp. 1--88, 2016.","0","0","0","1","2","7","0","0","1","0","paragraph"
"[5] D. Pedreshi, S. Ruggieri and F. Turini, “Discrimina-","0","0","0","1","3","9","0","0","3","0","paragraph"
"tion-aware Data Mining,” in Proceedings of the 14th ACM","0","0","0","1","3","9","0","0","3","0","paragraph"
"SIGKDD International Conference on Knowledge Discov-","0","0","0","1","2","6","0","0","2","0","paragraph"
"ery and Data Mining, Las Vegas, Nevada, USA, 2008.","0","0","0","1","2","9","0","0","5","0","paragraph"
"[6] Wikipedia,","0","0","0","1","2","2","0","0","1","0","paragraph"
"[Online].","0","0","0","1","3","1","0","0","1","0","paragraph"
"“List of cognitive biases,” June 2019.","0","0","0","1","3","6","0","0","2","0","paragraph"
"Available: https://en.wikipedia.org/wiki/","0","0","0","1","3","2","0","0","0","0","paragraph"
"List_of_cognitive_biases.","0","0","0","1","2","1","0","0","1","0","paragraph"
"28","1","0","1","1","2","1","1","0","0","1","paragraph"
"[7] Google,","0","0","0","1","2","2","0","0","1","0","paragraph"
"[Online].","0","0","0","1","3","1","0","0","1","0","paragraph"
"“Fairness: Identifying Bias,” June 2019.","0","0","0","1","3","5","0","1","2","0","paragraph"
"Available: https://developers.google.com/","0","0","0","1","3","2","0","0","0","0","paragraph"
"machine-learning/crash-course/fairness/identifying-bias.","0","0","0","1","0","1","0","1","1","0","paragraph"
"[8] M. Konnikova, “The Hazards of Going on Autopilot,” June","0","0","0","1","2","10","0","1","3","0","paragraph"
"[Online]. Available: https://www.newyorker.com/","0","0","0","1","3","3","0","0","1","0","paragraph"
"science/maria-konnikova/hazards-automation.","0","0","0","1","0","1","0","0","1","0","paragraph"
"[9] S. Venkatasubramanian, A. Friedler and C. Scheide-","0","0","0","1","2","8","0","0","3","1","paragraph"
"gger, “On the (im)possibility","0","0","0","1","3","4","0","0","1","0","paragraph"
"abs/1609.07236, 2016.","0","0","0","1","0","2","0","0","0","0","paragraph"
"of fairness,” CoRR, vol.","0","0","0","1","3","4","0","0","1","0","paragraph"
"[10] D. Pedreshi, S.","0","0","0","1","2","4","0","0","1","0","paragraph"
"tion-aware data","0","0","0","1","0","2","0","0","1","0","paragraph"
"Ruggieri and F. Turini, “Discrimina-","0","0","0","1","3","5","0","0","2","0","paragraph"
"mining,” Proceeding of the 14th ACM","0","0","0","1","3","6","0","1","2","0","paragraph"
"SIGKDD international conference on Knowledge discov-","0","0","0","1","3","6","0","0","2","0","paragraph"
"ery and data mining - KDD 08, p. 560, 2008.","0","0","0","1","3","10","0","0","2","1","paragraph"
"[11] C. Dwork, M. Hardt, T. Pitassi, O. Reingold and R. Zemel,","0","0","0","1","2","12","0","0","1","1","paragraph"
"“Fairness Through Awareness,” 2011.","0","0","0","1","3","4","0","0","2","0","paragraph"
"[12] M. Hardt, E. Price and N. Srebro, “Equality of Opportunity","0","0","0","1","3","11","0","0","5","1","paragraph"
"in Supervised Learning,” pp. 1--22, 2016.","0","0","0","1","2","6","0","0","2","1","paragraph"
"[13] S. Barocas, M. Hardt and A. Narayanan, “Limitations and","0","0","0","1","3","10","0","0","4","0","paragraph"
"Opportunities,” 2018.","0","0","0","1","2","2","0","0","1","0","paragraph"
"[14] F. Kamiran and T. Calders, “Data preprocessing techniques","0","0","0","1","3","9","0","1","3","1","paragraph"
"for classification without discrimination,” Knowledge and","0","0","0","1","3","6","0","0","2","0","paragraph"
"Information Systems, pp. 1--33, 2012.","0","0","0","1","2","5","0","0","2","1","paragraph"
"[15] T. Adel and A. Weller, “One-network Adversarial Fairness,”","0","0","0","1","3","9","0","0","3","2","paragraph"
"Aaai, 2019.","0","0","0","1","2","2","0","0","1","0","paragraph"
"[16] F. P. Calmon, D. Wei, K. N. Ramamurthy and K. R. Varsh-","0","0","0","1","2","13","0","0","4","0","paragraph"
"ney, “Optimized Data Pre-Processing for Discrimination","0","0","0","1","3","6","0","0","3","0","paragraph"
"Prevention,” in Advances in Neural Information Process-","0","0","0","1","2","7","0","0","3","0","paragraph"
"ing Systems 30, 2017.","0","0","0","1","2","4","0","0","1","0","paragraph"
"[17] R. R. Andridge and R. J. Little, “A Review of Hot Deck Impu-","0","0","0","1","2","14","0","0","4","1","paragraph"
"tation for Survey Non-response,” International Statistical","0","0","0","1","3","6","0","0","3","0","paragraph"
"Review, no. 78, pp. 40-64, 2010.","0","0","0","1","2","6","0","0","2","0","paragraph"
"29","1","0","1","1","2","1","1","0","0","1","paragraph"
"[18] M. B. Zafar, I. Valera, M. G. Rodriguez and K. P. Gummadi,","0","0","0","1","2","13","0","0","4","1","paragraph"
"“Fairness Constraints: Mechanisms for Fair Classifica-","0","0","0","1","3","6","0","0","3","0","paragraph"
"tion,” in Proceedings of the 20th International Conference","0","0","0","1","3","8","0","0","3","0","paragraph"
"on Artificial Intelligence and Statistics, 2017.","0","0","0","1","2","6","0","0","2","0","paragraph"
"[19] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D.","0","0","0","1","2","10","0","0","5","1","paragraph"
"Warde-Farley, S. Ozair, A. Courville and Y. Bengio, “Gener-","0","0","0","1","3","9","0","0","5","0","paragraph"
"ative Adversarial Nets,” in Advances in Neural Information","0","0","0","1","3","8","0","0","3","0","paragraph"
"Processing Systems 27, 2014.","0","0","0","1","2","4","0","0","1","0","paragraph"
"[20] B. H. Zhang, B. Lemoine and M. Mitchell, “Mitigating","0","0","0","1","3","10","0","1","3","0","paragraph"
"Unwanted Biases with Adversarial Learning,” Association","0","0","0","1","2","6","0","0","3","0","paragraph"
"for the Advancement of Artificial Intelligence, 2018.","0","0","0","1","2","7","0","0","2","0","paragraph"
"[21] C. Wadsworth, F. Vera and C. Piech, “Achieving Fairness","0","0","0","1","3","10","0","1","4","1","paragraph"
"through Adversarial Learning: an Application to Recidi-","0","0","0","1","3","7","0","0","2","0","paragraph"
"vism Prediction,” CoRR, 2018.","0","0","0","1","2","4","0","0","2","0","paragraph"
"[22] G. Louppe, M. Kagan and K. Cranmer, “Learning to Pivot","0","0","0","1","3","11","0","1","4","1","paragraph"
"with Adversarial Networks,” in Proceedings of the 31st","0","0","0","1","2","8","0","0","3","0","paragraph"
"International Conference on Neural Information Process-","0","0","0","1","2","6","0","0","2","0","paragraph"
"ing Systems, 2017.","0","0","0","1","2","3","0","0","1","0","paragraph"
"[23] J. Chen, N. Kallus, X. Mao, C. Tech and G. Svacha, “Fairness","0","0","0","1","3","13","0","0","6","1","paragraph"
"Under Unawareness: Assessing Disparity When Protected","0","0","0","1","2","6","0","1","2","0","paragraph"
"Class Is Unobserved,” 2019.","0","0","0","1","2","4","0","0","1","0","paragraph"
"[24] M. Donini, S. Ben-David, M. Pontil and J. Shawe-Taylor,","0","0","0","1","2","10","0","0","4","1","paragraph"
"“An efficient method to impose fairness in linear models,”","0","0","0","1","3","9","0","1","3","0","paragraph"
"in NIPS Workshop on Prioritising Online Content, 2017.","0","0","0","1","2","8","0","0","2","0","paragraph"
"[25] Council of Europe, Convention for the Protection of","0","0","0","1","2","9","0","0","4","1","paragraph"
"Human Rights and Fundamental Freedoms.","0","0","0","1","2","5","0","0","2","0","paragraph"
"[26] Council of Europe, Charter of fundamental rights of the","0","0","0","1","3","10","0","0","4","1","paragraph"
"European Union (2012/C 326/02).","0","0","0","1","2","4","0","0","1","0","paragraph"
"[27] Council of Europe, Directive 2004/113/EC of 13 Decem-","0","0","0","1","2","9","0","0","3","2","paragraph"
"ber 2004 implementing the principle of equal treatment","0","0","0","1","0","8","0","1","3","0","paragraph"
"between men and women in the access to and supply of","0","0","0","1","0","11","0","0","4","0","paragraph"
"goods and services, Article 5.","0","0","0","1","3","5","0","0","2","0","paragraph"
"[28] WP29, Guidelines on automated individual decision-mak-","0","0","0","1","3","7","0","1","1","1","paragraph"
"ing and profiling for the purposes of Regulation 2016/679.","0","0","0","1","3","9","0","1","2","0","paragraph"
"30","1","0","1","1","2","1","1","0","0","1","paragraph"
"[29] “French Insurance Code, Article L.113-2”.","0","0","0","1","3","6","0","0","1","1","paragraph"
"[30] R. K. E. Bellamy, K. Dey and H. Michael, “AI Fairness 360:","0","0","0","1","2","13","0","0","4","1","paragraph"
"An Extensible Toolkit for Detecting, Understanding, and","0","0","0","1","2","7","0","0","3","0","paragraph"
"Mitigating Unwanted Algorithmic Bias,” 2018.","0","0","0","1","2","5","0","1","1","0","paragraph"
"[31] L. E. Celis, L. Huang, V. Keswani and N. K. Vishnoi, “Classi-","0","0","0","1","3","13","0","0","5","0","paragraph"
"fication with Fairness Constraints: A Meta-Algorithm with","0","0","0","1","3","7","0","0","3","0","paragraph"
"Provable Guarantees,” CoRR, 2018.","0","0","0","1","2","4","0","0","2","0","paragraph"
"[32] M. Hardt, E. Price and N. Srebro, “Equality of Opportunity","0","0","0","1","3","11","0","0","5","1","paragraph"
"in Supervised Learning,” in Advances in Neural Informa-","0","0","0","1","2","8","0","0","3","0","paragraph"
"tion Processing Systems 29, 2016.","0","0","0","1","2","5","0","0","1","0","paragraph"
"[33] CNIL, Delib. n°2013-212 concerning automated processing","0","0","0","1","3","7","0","2","3","1","paragraph"
"of personal data relating to the execution, management","0","0","0","1","0","8","0","1","2","0","paragraph"
"and enforcement of contracts implemented by insurance,","0","0","0","1","0","7","0","1","3","0","paragraph"
"capitalization, reinsurance, insurance","0","0","0","1","0","3","0","0","3","0","paragraph"
"through their intermediaries.","0","0","0","1","0","3","0","0","1","0","paragraph"
"assistance and","0","0","0","1","0","2","0","0","1","0","paragraph"
"[34] J. Chen and J. Shao, “Nearest Neighbor Imputation for","0","0","0","1","3","10","0","0","3","1","paragraph"
"Survey Data,” Journal of Official Statistics, vol. 16, no. 2,","0","0","0","1","2","10","0","0","4","2","paragraph"
"pp. 113-131, 2000.","0","0","0","1","0","3","0","0","1","1","paragraph"
"31","1","0","1","1","2","1","1","0","0","1","paragraph"
"Experts","1","1","1","1","2","1","0","0","1","0","heading"
"Boris RUF boris.ruf@axa.com","0","0","1","0","3","3","0","0","1","0","paragraph"
"Research Data Scientist","0","0","0","1","2","3","0","0","1","0","paragraph"
"Vincent GRARI vincent.grari@axa.com","0","0","1","0","3","3","0","0","1","0","paragraph"
"Research Data Scientist","0","0","0","1","2","3","0","0","1","0","paragraph"
"Sponsors","1","1","1","1","2","1","0","0","1","0","heading"
"Marcin DETYNIECKI","1","0","1","1","2","2","0","0","1","0","paragraph"
"Chief Data Scientist","0","0","0","1","2","3","0","0","1","0","paragraph"
"marcin.detyniecki@axa.com","0","0","1","1","0","1","0","0","0","0","paragraph"
"32","1","0","1","1","2","1","1","0","0","1","paragraph"
"Roland SCHARRER roland.scharrer@axa.com","0","0","1","0","3","3","0","0","1","0","paragraph"
"Chief Technology Innovation Officer","0","0","0","1","2","4","0","0","1","0","paragraph"
"Tous droits réservés – AXA GROUP OPERATION","0","0","1","1","3","7","0","1","2","0","paragraph"
"81 rue mstislav rostropovitch 75017 Paris - 2019","0","0","1","1","3","8","0","0","1","2","paragraph"
"« Le Code de la propriété intellectuelle interdit les copies ou reproductions","0","0","1","1","3","12","0","0","3","0","paragraph"
"destinées à une utilisation collective. Toute représentation ou reproduction","0","0","1","1","3","9","0","0","3","0","paragraph"
"intégrale ou partielle faite par quelque procédé que ce soit, sans le consente-","0","0","1","1","0","13","0","0","3","0","paragraph"
"ment de l’auteur ou de ses ayant droit ou ayant cause, est illicite et constitue","0","0","1","1","0","15","0","0","3","0","paragraph"
"une contrefaçon, aux termes des articles L.335-2 et suivants du Code de la pro-","0","0","1","1","3","14","0","1","3","0","paragraph"
"priété intellectuelle. »","0","0","1","1","0","3","0","0","1","0","paragraph"
"Achevé d’imprimer en 2019","0","0","1","1","3","4","0","0","1","0","paragraph"
"34","1","0","1","1","2","1","1","0","0","1","paragraph"
