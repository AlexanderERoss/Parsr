import argparse
import os
import pandas as pd
from sklearn import metrics
from sklearn.feature_selection import RFECV
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn_porter import Porter


def dt_model(parameters, X, y, score_function):
    clf = DecisionTreeClassifier(min_samples_leaf=parameters['min_samples_leaf'],
                                 min_samples_split=parameters['min_samples_split'],
                                 criterion=parameters['criterion'],
                                 splitter='best')
    selector = RFECV(clf, step=1, cv=10, scoring=metrics.make_scorer(score_function)).fit(X, y)
    return selector

def rf_model(parameters, X, y, score_function):
    clf = RandomForestClassifier(n_estimators=parameters['n_estimators'],
                                 min_samples_leaf=parameters['min_samples_leaf'],
                                 min_samples_split=parameters['min_samples_split'],
                                 criterion=parameters['criterion'],
                                 random_state=0)
    selector = RFECV(clf, step=1, cv=10, scoring=metrics.make_scorer(score_function)).fit(X, y)
    return selector

def adaboost_model(parameters, X, y):
    estimator = DecisionTreeClassifier(min_samples_leaf=parameters['min_samples_leaf'],
                                       min_samples_split=parameters['min_samples_split'],
                                       criterion=parameters['criterion'],
                                       splitter='best')
    clf = AdaBoostClassifier(base_estimator=estimator, n_estimators=100, random_state=0).fit(X, y)
    return clf

def export_model_to_js(selector, filename):
    porter = Porter(selector.estimator_, language='js')
    output = porter.export(embed_data=True)
    with open(os.path.join(args.out_dir, filename), mode='w+', encoding='utf8') as f:
        f.write('export ' + output)


parser = argparse.ArgumentParser(description='Train a decision tree to recognize headings and their levels.')
parser.add_argument('dataset_dir', help='folder containing the .csv files generated by build_dataset.py')
parser.add_argument('out_dir', help='folder in which to save the two trained models')
args = parser.parse_args()

dataset_dir = args.dataset_dir
paths = os.listdir(dataset_dir)
dataset = []

for path in paths:
    df = pd.read_csv(os.path.join(dataset_dir, path), header=0)
    df['font_size'] = df['font_size'].apply(lambda x: round(x, 2))
    df['label'] = df['label'].apply(lambda x: 1 if x == 'heading' else 0)

    dataset.append(df[['is_different_style', 'is_font_bigger', 'is_font_unique',
                       'text_case', 'word_count', 'different_color',
                       'is_number', 'font_size', 'is_bold',
                       'level', 'label']])

df_dataset = pd.concat(dataset)
X_heading = df_dataset[['is_different_style', 'is_font_bigger', 'is_font_unique',
                        'text_case', 'word_count', 'different_color',
                        'is_number']].to_numpy()
y_heading = list(df_dataset['label'])

# only taking the headings into account
df_lvl = df_dataset.loc[df_dataset['label']==1].reset_index()
X_lvl = df_lvl[['font_size', 'is_bold', 'text_case',
                'is_font_bigger', 'different_color']].to_numpy()
y_lvl = list(df_lvl['level'])

X_train1, X_test1, y_train1, y_test1 = train_test_split(X_heading, y_heading, test_size=0.2)
X_train2, X_test2, y_train2, y_test2 = train_test_split(X_lvl, y_lvl, test_size=0.2)

# those parameters are found through grid search
parameters_heading = {'n_estimators': 48, 'min_samples_leaf': 1, 'min_samples_split': 7, 'criterion': 'entropy'}
parameters_lvl = {'min_samples_leaf': 1, 'min_samples_split': 2, 'criterion': 'entropy'}              

# computing the models
selector_heading = rf_model(parameters_heading, X_heading, y_heading, metrics.f1_score)
selector_lvl = dt_model(parameters_lvl, X_lvl, y_lvl, metrics.accuracy_score)

# exporting the models
export_model_to_js(selector_heading, 'model.js')
export_model_to_js(selector_lvl, 'model_level.js')

# evaluating the performance
y_pred_heading = selector_heading.predict(X_test1)
y_pred_lvl = selector_lvl.predict(X_test2)
print('precision (heading detection):', metrics.precision_score(y_test1, y_pred_heading))
print('recall (heading detection):', metrics.recall_score(y_test1, y_pred_heading))
print('f1-score (heading detection):', metrics.f1_score(y_test1, y_pred_heading))
print('accuracy (headings level):', metrics.accuracy_score(y_test2, y_pred_lvl))
        